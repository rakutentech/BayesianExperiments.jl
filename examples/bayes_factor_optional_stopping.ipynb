{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Factor Experiment with Optional Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter: @showprogress\n",
    "using DataFrames\n",
    "\n",
    "using PrettyTables\n",
    "using Plots\n",
    "using Random\n",
    "using BayesianExperiments\n",
    "\n",
    "# number of columns in a dataframe to show \n",
    "ENV[\"COLUMNS\"] = 200;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional stopping refers to the practice of peeking at data and make decision whether or not to continue an experiment. Such practice is usually prohibited in the frequentist AB testing framework. By using simulation-based result, **Rouder (2014)**[2] showed that a Bayes factor experiment with optional stopping can be valid with proper interpretation of the Bayesian quantities. \n",
    "\n",
    "This notebook follows the examples in **Schönbrodt et al. (2016)**[1] to conduct the error analysis of Bayes factor based experiment with optional stopping.\n",
    "\n",
    "The simulation will be conducted by following steps:\n",
    "\n",
    "1. Choose a threshold of Bayes factor for decision making. For example, if the threshold is set to 10, when a Bayes factor of $\\text{BF}_{10}$ is larger than 10, or less than 1/10, we decide we have collected enough evidence and stop the experiment.\n",
    "2. Choose a prior distribituion for the effect size under $H_1$. We will use the `StudentTEffectSize` model in the package. You can check the definition of `NormalEffectSize` model from the docstring by typing `?NormalEffectSize`.\n",
    "3. Run a minimum number of steps (20 as the same in the paper), increase the sample size. Compute the bayes factor at each step.\n",
    "4. As soon as the bayes factor value reached or exceeded the one of the thresholds as set in (1), or the maximum number of steps is reached, we will stop the experiment.\n",
    "\n",
    "Some constants used in the simulation:\n",
    "\n",
    "* Number of simulations: 5000\n",
    "* Minimum number of steps: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation function can be quickly created based on our package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printtable (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simulate(δ, n, σ0; r=0.707, thresh=9, minsample=20)\n",
    "    # we will use two-sided decision rule for bayes factor\n",
    "    rule = TwoSidedBFThresh(thresh)\n",
    "    \n",
    "    # the prior distribution of effect size,\n",
    "    # r is the standard deviation\n",
    "    model = StudentTEffectSize(r=r)\n",
    "    \n",
    "    # setup the experiment\n",
    "    experiment = ExperimentBF(model=model, rule=rule)\n",
    "    \n",
    "    # create a sample with size n, the effect size is \n",
    "    # specified as δ\n",
    "    xs = rand(Normal(δ, 1), n)\n",
    "    \n",
    "    i = 0\n",
    "    # specify the stopping condition\n",
    "    while (i < n) & (experiment.winner === nothing)\n",
    "        i += 1\n",
    "        \n",
    "        # if minimum number of sample is not reached, \n",
    "        # keep collecting data\n",
    "        if i < minsample\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        stats = NormalStatistics(xs[1:i])\n",
    "        experiment.stats = stats\n",
    "        decide!(experiment)\n",
    "    end\n",
    "    experiment\n",
    "end\n",
    "\n",
    "# df table print helper\n",
    "printtable(df) = pretty_table(df, tf=tf_markdown, nosubheader=true, header_crayon=Crayon(bold=:false))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case when alternative $\\delta = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When alternative $\\delta > 0$, the error rate relates to the false positive rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(paramsgrid) = 12\n"
     ]
    }
   ],
   "source": [
    "#deltas = collect(range(0, 1.5, step=0.2));\n",
    "delta = 0.0\n",
    "rs = [0.707, 1.0, 1.414];\n",
    "threshs = [3, 5, 7, 10];\n",
    "totalnum = length(rs)*length(threshs);\n",
    "\n",
    "paramsgrid = reshape(collect(Base.Iterators.product(rs, threshs)), (totalnum, 1));\n",
    "paramsgrid = [(r=r, thresh=thresh) for (r, thresh) in paramsgrid];\n",
    "@show length(paramsgrid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:58\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "n =  1000\n",
    "ns = 5000\n",
    "minsample = 20\n",
    "\n",
    "sim_result1 = DataFrame(\n",
    "    delta=Float64[], \n",
    "    r=Float64[], \n",
    "    thresh=Float64[], \n",
    "    num_sim=Int64[], \n",
    "    num_null=Int64[], \n",
    "    num_alt=Int64[],\n",
    "    err_rate=Float64[], \n",
    "    avg_sample_size=Int64[])\n",
    "\n",
    "@showprogress for params in paramsgrid\n",
    "    delta = 0\n",
    "    r = params.r\n",
    "    thresh = params.thresh\n",
    "    winners = []\n",
    "    samplesizes = []\n",
    "    for _ in 1:ns\n",
    "        experiment = simulate(delta, n, r, thresh=thresh, minsample=minsample)\n",
    "        push!(winners, experiment.winner)\n",
    "        push!(samplesizes, experiment.stats.n)\n",
    "    end\n",
    "    \n",
    "    num_null = sum(winners .== \"null\")\n",
    "    num_alt = sum(winners .== \"alternative\")\n",
    "    \n",
    "    err_rate = num_alt/ns\n",
    "    avg_sample_size = mean(samplesizes)\n",
    "    push!(sim_result1, (delta, r, thresh, ns, num_null, num_alt, err_rate, convert(Int64, round(avg_sample_size))))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\u001b[22m delta \u001b[0m|\u001b[22m     r \u001b[0m|\u001b[22m thresh \u001b[0m|\u001b[22m num_sim \u001b[0m|\u001b[22m num_null \u001b[0m|\u001b[22m num_alt \u001b[0m|\u001b[22m err_rate \u001b[0m|\u001b[22m avg_sample_size \u001b[0m|\n",
      "|-------|-------|--------|---------|----------|---------|----------|-----------------|\n",
      "|   0.0 | 0.707 |    3.0 |    5000 |     4689 |     311 |   0.0622 |              24 |\n",
      "|   0.0 |   1.0 |    3.0 |    5000 |     4662 |     338 |   0.0676 |              24 |\n",
      "|   0.0 | 1.414 |    3.0 |    5000 |     4698 |     302 |   0.0604 |              24 |\n",
      "|   0.0 | 0.707 |    5.0 |    5000 |     4712 |     288 |   0.0576 |              47 |\n",
      "|   0.0 |   1.0 |    5.0 |    5000 |     4718 |     282 |   0.0564 |              48 |\n",
      "|   0.0 | 1.414 |    5.0 |    5000 |     4688 |     311 |   0.0622 |              49 |\n",
      "|   0.0 | 0.707 |    7.0 |    5000 |     4753 |     238 |   0.0476 |             101 |\n",
      "|   0.0 |   1.0 |    7.0 |    5000 |     4777 |     218 |   0.0436 |              99 |\n",
      "|   0.0 | 1.414 |    7.0 |    5000 |     4765 |     227 |   0.0454 |             102 |\n",
      "|   0.0 | 0.707 |   10.0 |    5000 |     4752 |     181 |   0.0362 |             210 |\n",
      "|   0.0 |   1.0 |   10.0 |    5000 |     4729 |     210 |    0.042 |             206 |\n",
      "|   0.0 | 1.414 |   10.0 |    5000 |     4745 |     191 |   0.0382 |             208 |\n"
     ]
    }
   ],
   "source": [
    "printtable(sim_result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case when alternative $\\delta > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a grid of combinations of all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(paramsgrid) = 60\n",
      "paramsgrid[1:5] = NamedTuple{(:delta, :r, :thresh),Tuple{Float64,Float64,Int64}}[(delta = 0.1, r = 0.707, thresh = 3), (delta = 0.3, r = 0.707, thresh = 3), (delta = 0.5, r = 0.707, thresh = 3), (delta = 0.7, r = 0.707, thresh = 3), (delta = 0.9, r = 0.707, thresh = 3)]\n"
     ]
    }
   ],
   "source": [
    "deltas = collect(range(0.1, 1.0, step=0.2));\n",
    "rs = [0.707, 1.0, 1.414];\n",
    "threshs = [3, 5, 7, 10];\n",
    "totalnum = length(deltas)*length(rs)*length(threshs);\n",
    "\n",
    "paramsgrid = reshape(collect(Base.Iterators.product(deltas, rs, threshs)), (totalnum, 1));\n",
    "paramsgrid = [(delta=delta, r=r, thresh=thresh) for (delta, r, thresh) in paramsgrid]\n",
    "@show length(paramsgrid);\n",
    "@show paramsgrid[1:5];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation is similar to the $\\delta=0$ case. When alternative $\\delta > 0$, the error rate relates to the false negative evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:31\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "n =  1000\n",
    "ns = 5000\n",
    "minsample = 20\n",
    "\n",
    "sim_result2 = DataFrame(\n",
    "    delta=Float64[], \n",
    "    r=Float64[], \n",
    "    thresh=Float64[], \n",
    "    num_sim=Int64[], \n",
    "    num_null=Int64[], \n",
    "    num_alt=Int64[],\n",
    "    err_rate=Float64[], \n",
    "    avg_sample_size=Int64[])\n",
    "\n",
    "@showprogress for params in paramsgrid\n",
    "    delta=params.delta\n",
    "    r = params.r\n",
    "    thresh = params.thresh\n",
    "    winners = []\n",
    "    samplesizes = []\n",
    "    for _ in 1:ns\n",
    "        experiment = simulate(delta, n, r, thresh=thresh, minsample=minsample)\n",
    "        push!(winners, experiment.winner)\n",
    "        push!(samplesizes, experiment.stats.n)\n",
    "    end\n",
    "    \n",
    "    num_null = sum(winners .== \"null\")\n",
    "    num_alt = sum(winners .== \"alternative\")\n",
    "    err_rate = 1-num_alt/ns\n",
    "    avg_sample_size = mean(samplesizes)\n",
    "    push!(sim_result2, (delta, r, thresh, ns, num_null, num_alt, \n",
    "            err_rate, convert(Int64, round(avg_sample_size))))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation result when $\\delta=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\u001b[22m delta \u001b[0m|\u001b[22m     r \u001b[0m|\u001b[22m thresh \u001b[0m|\u001b[22m num_sim \u001b[0m|\u001b[22m num_null \u001b[0m|\u001b[22m num_alt \u001b[0m|\u001b[22m err_rate \u001b[0m|\u001b[22m avg_sample_size \u001b[0m|\n",
      "|-------|-------|--------|---------|----------|---------|----------|-----------------|\n",
      "|   0.5 | 0.707 |    3.0 |    5000 |      694 |    4306 |   0.1388 |              26 |\n",
      "|   0.5 | 0.707 |    5.0 |    5000 |       82 |    4918 |   0.0164 |              33 |\n",
      "|   0.5 | 0.707 |    7.0 |    5000 |        0 |    5000 |      0.0 |              36 |\n",
      "|   0.5 | 0.707 |   10.0 |    5000 |        0 |    5000 |      0.0 |              39 |\n",
      "|   0.5 |   1.0 |    3.0 |    5000 |      674 |    4326 |   0.1348 |              25 |\n",
      "|   0.5 |   1.0 |    5.0 |    5000 |       90 |    4910 |    0.018 |              33 |\n",
      "|   0.5 |   1.0 |    7.0 |    5000 |        3 |    4997 |   0.0006 |              37 |\n",
      "|   0.5 |   1.0 |   10.0 |    5000 |        0 |    5000 |      0.0 |              40 |\n",
      "|   0.5 | 1.414 |    3.0 |    5000 |      746 |    4254 |   0.1492 |              26 |\n",
      "|   0.5 | 1.414 |    5.0 |    5000 |       84 |    4916 |   0.0168 |              34 |\n",
      "|   0.5 | 1.414 |    7.0 |    5000 |        0 |    5000 |      0.0 |              36 |\n",
      "|   0.5 | 1.414 |   10.0 |    5000 |        0 |    5000 |      0.0 |              40 |\n"
     ]
    }
   ],
   "source": [
    "sim_result2 |>\n",
    "    df -> filter(x->x.delta==0.5, df)|>\n",
    "    df -> sort(df, [:delta, :r]) |>\n",
    "    printtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the simulation result with Type I & II Error and FDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pointed out by [2], we can evaluate the simulation result from the perspective of false discovery rate. Here we assume there is a 50-50 chance that the data is from either the null model or alternative model. \n",
    "\n",
    "We can merge the two simulations results by the prior standard deviation $r$ and threshold of bayes factor. In the merged dataframe, each row represents a simulation with the 5000 samples from the null model and 5000 samples from the alternative model with the corresponding parameters ($r$, $thresh$, $\\delta_1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_result = leftjoin(sim_result1, sim_result2, \n",
    "    on=[:r, :thresh, :num_sim],\n",
    "    renamecols= \"_0\" => \"_1\"\n",
    ");\n",
    "\n",
    "sim_result.num_dis = sim_result.num_alt_0 + sim_result.num_alt_1;\n",
    "sim_result.num_false_dis = sim_result.num_alt_0;\n",
    "sim_result.fdr = sim_result.num_false_dis ./ sim_result.num_dis;\n",
    "\n",
    "sim_result.type1_error = sim_result.num_alt_0 ./ sim_result.num_sim;\n",
    "#sim_result.type2_error = 1 .- sim_result.num_alt_1 ./ sim_result.num_sim;\n",
    "sim_result.power = sim_result.num_alt_1 ./ sim_result.num_sim;\n",
    "\n",
    "sim_result = sim_result |>\n",
    "    df -> select(df, [:delta_1, :r, :thresh, :num_sim, :num_null_0, :num_alt_0, \n",
    "        :num_null_1, :num_alt_1, :type1_error, :power, :fdr]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_result.num_dis = sim_result.num_alt_0 + sim_result.num_alt_1;\n",
    "sim_result.num_false_dis = sim_result.num_alt_0;\n",
    "sim_result.fdr = sim_result.num_false_dis ./ sim_result.num_dis;\n",
    "\n",
    "sim_result.type1_error = sim_result.num_alt_0 ./ sim_result.num_sim;\n",
    "sim_result.type2_error = 1 .- sim_result.num_alt_1 ./ sim_result.num_sim;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_result = sim_result |>\n",
    "    df -> select(df, [:delta_1, :r, :thresh, :num_sim, :num_alt_0, :num_alt_1, :type1_error, :power, :fdr]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples from merged dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\u001b[22m delta_1 \u001b[0m|\u001b[22m     r \u001b[0m|\u001b[22m thresh \u001b[0m|\u001b[22m num_sim \u001b[0m|\u001b[22m num_alt_0 \u001b[0m|\u001b[22m num_alt_1 \u001b[0m|\u001b[22m type1_error \u001b[0m|\u001b[22m  power \u001b[0m|\u001b[22m       fdr \u001b[0m|\n",
      "|---------|-------|--------|---------|-----------|-----------|-------------|--------|-----------|\n",
      "|     0.1 | 0.707 |    3.0 |    5000 |       311 |       568 |      0.0622 | 0.1136 |  0.353811 |\n",
      "|     0.1 | 0.707 |    5.0 |    5000 |       288 |       812 |      0.0576 | 0.1624 |  0.261818 |\n",
      "|     0.1 | 0.707 |    7.0 |    5000 |       238 |      1335 |      0.0476 |  0.267 |  0.151303 |\n",
      "|     0.1 | 0.707 |   10.0 |    5000 |       181 |      2102 |      0.0362 | 0.4204 | 0.0792816 |\n",
      "|     0.1 |   1.0 |    3.0 |    5000 |       338 |       542 |      0.0676 | 0.1084 |  0.384091 |\n",
      "|     0.1 |   1.0 |    5.0 |    5000 |       282 |       810 |      0.0564 |  0.162 |  0.258242 |\n",
      "|     0.1 |   1.0 |    7.0 |    5000 |       218 |      1329 |      0.0436 | 0.2658 |  0.140918 |\n",
      "|     0.1 |   1.0 |   10.0 |    5000 |       210 |      2035 |       0.042 |  0.407 | 0.0935412 |\n",
      "|     0.3 |   1.0 |    3.0 |    5000 |       338 |      2399 |      0.0676 | 0.4798 |  0.123493 |\n",
      "|     0.3 |   1.0 |    5.0 |    5000 |       282 |      3843 |      0.0564 | 0.7686 | 0.0683636 |\n",
      "|     0.3 |   1.0 |    7.0 |    5000 |       218 |      4762 |      0.0436 | 0.9524 | 0.0437751 |\n",
      "|     0.3 |   1.0 |   10.0 |    5000 |       210 |      4990 |       0.042 |  0.998 | 0.0403846 |\n"
     ]
    }
   ],
   "source": [
    "sim_result |>\n",
    "    df -> filter(\n",
    "        x -> ((x.delta_1 == 0.1) .& (x.r == 0.707)) .|\n",
    "             ((x.delta_1 == 0.1) .& (x.r == 1.0)) .|\n",
    "             ((x.delta_1 == 0.3) .& (x.r == 1.0))\n",
    "            , df) |>\n",
    "    df -> sort(df, [:delta_1, :r, :thresh]) |>\n",
    "    printtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Schönbrodt, Felix D., Eric-Jan Wagenmakers, Michael Zehetleitner, and Marco Perugini. \"Sequential hypothesis testing with Bayes factors: Efficiently testing mean differences.\" Psychological methods 22, no. 2 (2017): 322.\n",
    "2. Deng, Alex, Jiannan Lu, and Shouyuan Chen. \"Continuous monitoring of A/B tests without pain: Optional stopping in Bayesian testing.\" In 2016 IEEE international conference on data science and advanced analytics (DSAA), pp. 243-252. IEEE, 2016.\n",
    "3. Rouder, Jeffrey N. \"Optional stopping: No problem for Bayesians.\" Psychonomic bulletin & review 21, no. 2 (2014): 301-308."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.4",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
